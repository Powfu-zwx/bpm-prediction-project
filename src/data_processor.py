"""
æ•°æ®å¤„ç†æ¨¡å—
è´Ÿè´£æ•°æ®åŠ è½½ã€æ¸…æ´—ã€é¢„å¤„ç†å’Œç‰¹å¾å·¥ç¨‹
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest, f_regression
import joblib
import os
from .config import *

class DataProcessor:
    """éŸ³ä¹æ•°æ®å¤„ç†å™¨"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.feature_selector = None
        self.selected_features = None
        
    def generate_sample_data(self, n_samples=1000, random_state=42):
        """ç”Ÿæˆç¤ºä¾‹éŸ³ä¹æ•°æ®"""
        np.random.seed(random_state)
        
        # åˆ›å»ºéŸ³ä¹ç‰¹å¾
        data = {
            'danceability': np.random.beta(2, 5, n_samples),
            'energy': np.random.beta(2, 2, n_samples),
            'loudness': np.random.normal(-10, 5, n_samples),
            'speechiness': np.random.beta(1, 9, n_samples),
            'acousticness': np.random.beta(1, 3, n_samples),
            'instrumentalness': np.random.beta(1, 9, n_samples),
            'liveness': np.random.beta(1, 9, n_samples),
            'valence': np.random.beta(2, 2, n_samples),
            'duration_ms': np.random.normal(200000, 50000, n_samples),
        }
        
        df = pd.DataFrame(data)
        
        # ç¡®ä¿æ•°å€¼åœ¨åˆç†èŒƒå›´å†…
        df['loudness'] = np.clip(df['loudness'], -60, 0)
        df['duration_ms'] = np.clip(df['duration_ms'], 30000, 600000)
        
        # ç”ŸæˆBPMï¼ˆåŸºäºç‰¹å¾çš„å¤æ‚å…³ç³»ï¼‰
        df['tempo'] = (
            60 +
            df['energy'] * 80 +
            df['danceability'] * 60 +
            df['valence'] * 30 +
            np.random.normal(0, 15, n_samples)
        )
        
        df['tempo'] = np.clip(df['tempo'], 40, 200)
        
        return df
    
    def clean_data(self, df):
        """æ•°æ®æ¸…æ´—"""
        print("ğŸ§¹ å¼€å§‹æ•°æ®æ¸…æ´—...")
        
        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_values = df.isnull().sum()
        if missing_values.sum() > 0:
            print(f"å‘ç° {missing_values.sum()} ä¸ªç¼ºå¤±å€¼")
            df = df.dropna()
        
        # æ£€æŸ¥é‡å¤å€¼
        duplicates = df.duplicated().sum()
        if duplicates > 0:
            print(f"åˆ é™¤ {duplicates} ä¸ªé‡å¤è¡Œ")
            df = df.drop_duplicates()
            
        # æ£€æŸ¥å¼‚å¸¸å€¼ï¼ˆä½¿ç”¨IQRæ–¹æ³•ï¼‰
        for col in df.select_dtypes(include=[np.number]).columns:
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            
            outliers = ((df[col] < lower_bound) | (df[col] > upper_bound)).sum()
            if outliers > 0:
                print(f"{col}: å‘ç° {outliers} ä¸ªå¼‚å¸¸å€¼")
                
        print(f"âœ… æ•°æ®æ¸…æ´—å®Œæˆï¼æœ€ç»ˆæ•°æ®å½¢çŠ¶: {df.shape}")
        return df
    
    def feature_engineering(self, df):
        """ç‰¹å¾å·¥ç¨‹"""
        print("ğŸ”§ å¼€å§‹ç‰¹å¾å·¥ç¨‹...")
        
        # åˆ›å»ºæ–°ç‰¹å¾
        df['duration_min'] = df['duration_ms'] / 60000  # è½¬æ¢ä¸ºåˆ†é’Ÿ
        df['energy_danceability'] = df['energy'] * df['danceability']  # äº¤äº’ç‰¹å¾
        df['loudness_energy'] = df['loudness'] * df['energy']  # å“åº¦-èƒ½é‡äº¤äº’
        
        # åˆ›å»ºåˆ†ç±»ç‰¹å¾
        df['tempo_category'] = pd.cut(df['tempo'], 
                                    bins=[0, 90, 120, 140, 200], 
                                    labels=['æ…¢', 'ä¸­', 'å¿«', 'æå¿«'])
        
        # å¯¹åˆ†ç±»ç‰¹å¾è¿›è¡Œç‹¬çƒ­ç¼–ç 
        tempo_dummies = pd.get_dummies(df['tempo_category'], prefix='tempo_cat')
        df = pd.concat([df, tempo_dummies], axis=1)
        df = df.drop('tempo_category', axis=1)
        
        print(f"âœ… ç‰¹å¾å·¥ç¨‹å®Œæˆï¼æ–°ç‰¹å¾æ•°é‡: {df.shape[1]}")
        return df
    
    def select_features(self, X, y, k=10):
        """ç‰¹å¾é€‰æ‹©"""
        print(f"ğŸ¯ é€‰æ‹©å‰ {k} ä¸ªæœ€é‡è¦çš„ç‰¹å¾...")
        
        self.feature_selector = SelectKBest(score_func=f_regression, k=k)
        X_selected = self.feature_selector.fit_transform(X, y)
        
        # è·å–é€‰ä¸­çš„ç‰¹å¾åç§°
        feature_names = X.columns
        selected_mask = self.feature_selector.get_support()
        self.selected_features = feature_names[selected_mask].tolist()
        
        print(f"âœ… é€‰ä¸­çš„ç‰¹å¾: {self.selected_features}")
        return X_selected, self.selected_features
    
    def scale_features(self, X_train, X_test=None):
        """ç‰¹å¾æ ‡å‡†åŒ–"""
        print("ğŸ“Š è¿›è¡Œç‰¹å¾æ ‡å‡†åŒ–...")
        
        X_train_scaled = self.scaler.fit_transform(X_train)
        
        if X_test is not None:
            X_test_scaled = self.scaler.transform(X_test)
            return X_train_scaled, X_test_scaled
        
        return X_train_scaled
    
    def prepare_data(self, df, test_size=0.2, random_state=42):
        """å‡†å¤‡è®­ç»ƒå’Œæµ‹è¯•æ•°æ®"""
        print("ğŸ² åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®...")
        
        # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡å˜é‡
        X = df.drop('tempo', axis=1)
        y = df['tempo']
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=random_state
        )
        
        print(f"è®­ç»ƒé›†å½¢çŠ¶: {X_train.shape}, æµ‹è¯•é›†å½¢çŠ¶: {X_test.shape}")
        return X_train, X_test, y_train, y_test
    
    def save_preprocessor(self, filepath):
        """ä¿å­˜é¢„å¤„ç†å™¨"""
        joblib.dump({
            'scaler': self.scaler,
            'feature_selector': self.feature_selector,
            'selected_features': self.selected_features
        }, filepath)
        print(f"âœ… é¢„å¤„ç†å™¨å·²ä¿å­˜åˆ°: {filepath}")
    
    def load_preprocessor(self, filepath):
        """åŠ è½½é¢„å¤„ç†å™¨"""
        preprocessor = joblib.load(filepath)
        self.scaler = preprocessor['scaler']
        self.feature_selector = preprocessor['feature_selector']
        self.selected_features = preprocessor['selected_features']
        print(f"âœ… é¢„å¤„ç†å™¨å·²ä» {filepath} åŠ è½½")
